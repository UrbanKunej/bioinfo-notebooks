{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BA10I - viterbi learning\n",
    "\n",
    "#### Viterbi learning:\n",
    "\n",
    "If we **know x and Parameters, then we can construct the most likely path π** by applying the Viterbi algorithm to solve the **Decoding Problem**:\n",
    "\n",
    "(x, ?, Parameters) → π\n",
    "\n",
    "On the other hand, if we know **x and π**, then reconstructing **Parameters** amounts to solving the **HMM Parameter Estimation Problem**:\n",
    "\n",
    "(x, π, ?) → Parameters\n",
    "\n",
    "STOP and Think: What do the expressions (x, π, ?) → Parameters and (x, ?, Parameters) → π remind you of?\n",
    "\n",
    "*Expectation - maximization algorithm in k-means and hierarchical clustering*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**HMM Parameter Learning Problem:**\n",
    "\n",
    "*Estimate the parameters of an HMM explaining an emitted string.*\n",
    "\n",
    "**Input**:\n",
    "\n",
    "A string x = x1 ... xn emitted by an HMM with unknown transition and emission probabilities.\n",
    "\n",
    "\n",
    "**Output**:\n",
    "A transition matrix Transition and an emission matrix Emission that maximize Pr(x, π) over all possible transition and emission matrices and over all hidden paths π.\n",
    "\n",
    "\n",
    "Unfortunately, the HMM Parameter Learning Problem is **intractable**, and so we will instead develop a heuristic that is analogous to the Lloyd algorithm for k-means clustering. In that algorithm, we iterated two steps:\n",
    "\n",
    "1. “From Centers to Clusters”,\n",
    "\n",
    "        (Data, ?, Centers) → HiddenVector\n",
    "        \n",
    "        \n",
    "\n",
    "2. and “From Clusters to Centers”,\n",
    "\n",
    "        (Data, HiddenVector, ?) → Centers\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "As for **HMM parameter estimation**, we begin with an **initial random guess for Parameters**. Then, we use the **Viterbi algorithm to find the optimal hidden path π**:\n",
    "\n",
    "    (x, ?, Parameters) → π\n",
    "\n",
    "Once we know π, we will question our original choice of Parameters and apply our solution to the **HMM Parameter Estimation Problem to update Parameters based on x and π**:\n",
    "\n",
    "    (x, π, ?) → Parameters′\n",
    "\n",
    "We then **iterate over these two steps**, hoping that the estimated parameters are getting closer and closer to the parameters solving the HMM Parameter Learning Problem:\n",
    "\n",
    "$$(x, ?, Parameters)→ (x, π, Parameters)  → (x, π, ?)                     $$\n",
    "$$               → (x, π, Parameters′)  → (x, ?, Parameters′)          $$\n",
    "$$            → (x, π′, Parameters′)  → (x, π′, ?)                  $$\n",
    "$$          → (x, π′, Parameters′′) → . . .  $$\n",
    "\n",
    "\n",
    "This approach to learning the HMM’s parameters is called Viterbi learning.\n",
    "\n",
    "STOP and Think: Can Pr(x, π) decrease during Viterbi learning? When would you decide to stop the Viterbi learning algorithm?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we have not specified how Viterbi learning should terminate. In practice, there are various stopping rules to control its running time. For example, the algorithm can be stopped if the number of iterations exceeds a predefined threshold or if Pr(x, π) changes very little from one iteration to another.\n",
    "\n",
    "#### Code Challenge: Implement Viterbi learning for estimating the parameters of an HMM.\n",
    "\n",
    "**Input:**\n",
    "\n",
    "A number of iterations j, followed by a string x of symbols emitted by an HMM, followed by the HMM's alphabet Σ, followed by the HMM's states, followed by initial transition and emission matrices for the HMM.\n",
    "\n",
    "\n",
    "**Output:**\n",
    "Emission and transition matrices resulting from applying Viterbi learning for j iterations.\n",
    "\n",
    "    #Sample\n",
    "    \n",
    "        100\n",
    "        --------\n",
    "        zyzxzxxxzz\n",
    "        --------\n",
    "        x y z\n",
    "        --------\n",
    "        A B\n",
    "        --------\n",
    "            A\tB\n",
    "        A\t0.599\t0.401\t\n",
    "        B\t0.294\t0.706\t\n",
    "        --------\n",
    "            x\ty\tz\n",
    "        A\t0.424\t0.367\t0.209\t\n",
    "        B\t0.262\t0.449\t0.289\n",
    "    \n",
    "    Sample Output:\n",
    "\n",
    "            A\tB\n",
    "        A\t0.5\t0.5\t\n",
    "        B\t0.0\t1.0\t\n",
    "        --------\n",
    "            x\ty\tz\n",
    "        A\t0.333\t0.333\t0.333\t\n",
    "        B\t0.4\t0.1\t0.5\n",
    "        \n",
    "        \n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "### Simple sample dataset\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_parameters(pi, x, S, alpha):\n",
    "\n",
    "    S = len(states)\n",
    "    T = np.zeros(shape = (S, S))\n",
    "    E = np.zeros(shape = (S, len(alpha)))\n",
    "    E[pi[0]][x[0]] +=1\n",
    "    prev = pi[0]\n",
    "    for i in range(1, len(x)):\n",
    "        E[pi[i]][x[i]] +=1\n",
    "        T[prev][pi[i]] +=1\n",
    "        prev = pi[i]\n",
    "    for s in range(S):\n",
    "        if sum(E[s]) == 0:\n",
    "            E[s]+=1\n",
    "        E[s] = E[s]/sum(E[s])\n",
    "        if sum(T[s]) == 0:\n",
    "            T[s] += 1\n",
    "        T[s] = T[s]/sum(T[s])\n",
    "\n",
    "    return T,E\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Given a set of initial T, E matrices, apply viterbi algorithm for optimal hidden path\n",
    "\n",
    "def viterbi_hiddenpath(x, T, E, S):\n",
    "    \"\"\"returns max likelihood hidden path for emission string, given HMM\"\"\"\n",
    "\n",
    "    n = len(x)\n",
    "    viterbi = np.ones(shape = (S, n)) * -float('inf')\n",
    "    pointers = [[False for e in range(n)] for s in range(S)] \n",
    "    # init first column of viterbi with Pr_emission & 1/States\n",
    "    for state in range(S):\n",
    "        viterbi[state][0] = np.log(1/S) + E[state][x[0]]\n",
    "        pointers[state][0] = -1\n",
    "        \n",
    "    # Fill viterbi graph using dynamic programming\n",
    "    \n",
    "    for i in range(1,n):\n",
    "        for state in range(S):\n",
    "            for prev in range(S):\n",
    "                p_total = E[state][x[i]] + T[prev][state] + viterbi[prev][i-1]\n",
    "                if p_total > viterbi[state][i]:\n",
    "                    viterbi[state][i] = p_total\n",
    "                    pointers[state][i] = prev\n",
    "    # start backtrack from greatest probability in last column of viterbi\n",
    "    score = -float('inf')\n",
    "    for state in range(S):\n",
    "        if viterbi[state][n-1] > score:\n",
    "            last = state\n",
    "            score = viterbi[state][n-1]\n",
    "    path = [last]\n",
    "    # backtrack to recreate max likelihood hidden_path in reverse\n",
    "    i = n-1\n",
    "    while i > 0:\n",
    "        next = pointers[last][i]\n",
    "        path.append(next)\n",
    "        last = next\n",
    "        i -= 1\n",
    "    # reverse string to get hidden_path     \n",
    "    return path[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 [2, 1, 2, 0, 2, 0, 0, 0, 2, 2] ['x', 'y', 'z'] ['A', 'B']\n",
      "[[0.599 0.401]\n",
      " [0.294 0.706]]\n",
      "[[0.424 0.367 0.209]\n",
      " [0.262 0.449 0.289]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "with open(\"/Users/jasonmoggridge/Dropbox/Rosalind/Coursera_textbook_track/Course6/data/ba10i.sample.txt\") as f:\n",
    "    lines = [line.strip() for line in f]\n",
    "    # number of iterations 'iters'\n",
    "    iters = int(lines[0].strip())\n",
    "    # string emitted by HMM 'x'\n",
    "    x = lines[2].strip()\n",
    "    # alphabet of emissions from HMM in x; convert x to integers\n",
    "    alpha = lines[4].split()\n",
    "    x = [int(alpha.index(emission)) for emission in x]\n",
    "    \n",
    "    # states of HMM\n",
    "    states = lines[6].split()\n",
    "    S = len(states)\n",
    "    # Transition matrix\n",
    "    T = np.array([line.split()[1:] for line in lines[9:9+len(states)]], float)\n",
    "    #Emission matrix\n",
    "    E = np.array([line.split()[1:] for line in lines[9+len(states)+2:]], float)\n",
    "\n",
    "print(iters,x,alpha, states)\n",
    "print(T)\n",
    "print(E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'viterbi_hiddenpath' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-a1023aba1015>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# viterbi algo to find optimal hidden path | HMM, x\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mpi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mviterbi_hiddenpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;31m# estimate HMM parameters | pi, x\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimate_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'viterbi_hiddenpath' is not defined"
     ]
    }
   ],
   "source": [
    "for r in range(iters):\n",
    "    # viterbi algo to find optimal hidden path | HMM, x\n",
    "    pi = viterbi_hiddenpath(x, T, E, S)\n",
    "    # estimate HMM parameters | pi, x\n",
    "    T, E = estimate_parameters(pi, x, S, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "\n",
      "\n",
      "estimated Transition matrix:\n",
      "     A    B\n",
      "A  0.5  0.5\n",
      "B  0.0  1.0\n",
      "\n",
      "estimated Emission matrix:\n",
      "       x      y      z\n",
      "A  0.333  0.333  0.333\n",
      "B  0.400  0.100  0.500\n"
     ]
    }
   ],
   "source": [
    "print(pi)\n",
    "print(\"\\n\\nestimated Transition matrix:\")\n",
    "print(pd.DataFrame(np.around(T,3), index=states, columns = states))\n",
    "print(\"\\nestimated Emission matrix:\")\n",
    "print(pd.DataFrame(np.around(E,3), index=states, columns = alpha))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sample data solved. converges after 2 iterations.\n",
    "\n",
    "    pi=    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
    "\n",
    "\n",
    "    estimated Transition matrix:\n",
    "         A    B\n",
    "    A  0.5  0.5\n",
    "    B  0.0  1.0\n",
    "\n",
    "    estimated Emission matrix:\n",
    "           x      y      z\n",
    "    A  0.333  0.333  0.333\n",
    "    B  0.400  0.100  0.500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extra test dataset:\n",
    "\n",
    "##### Solution\n",
    "\n",
    "    Output:\n",
    "        A\tB\n",
    "    A \t0.0\t1.0 \n",
    "    B \t1.0\t0.0 \n",
    "    --------\n",
    "        x\ty\tz\n",
    "    A\t0.36\t0.14\t0.5 \n",
    "    B\t0.34\t0.34\t0.32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "### Extra test dataset\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi_learning(x, T, E, states, alpha):\n",
    "    \"\"\"Learn HMM given emission string x and initial HMM; return HMM: T, E matrices\"\"\"\n",
    "\n",
    "    def viterbi_hiddenpath(x, T, E, S):\n",
    "        \"\"\"returns max likelihood hidden path for emission string, given HMM\"\"\"\n",
    "\n",
    "        n = len(x)\n",
    "        viterbi = np.ones(shape = (S, n)) * -float('inf')\n",
    "        pointers = [[False for e in range(n)] for s in range(S)] \n",
    "        # init first column of viterbi with Pr_emission & 1/States\n",
    "        for state in range(S):\n",
    "            viterbi[state][0] = np.log(1/S) + E[state][x[0]]\n",
    "            pointers[state][0] = -1\n",
    "\n",
    "        # Fill viterbi graph using dynamic programming\n",
    "\n",
    "        for i in range(1,n):\n",
    "            for state in range(S):\n",
    "                for prev in range(S):\n",
    "                    p_total = E[state][x[i]] + T[prev][state] + viterbi[prev][i-1]\n",
    "                    if p_total > viterbi[state][i]:\n",
    "                        viterbi[state][i] = p_total\n",
    "                        pointers[state][i] = prev\n",
    "        # start backtrack from greatest probability in last column of viterbi\n",
    "        score = -float('inf')\n",
    "        for state in range(S):\n",
    "            if viterbi[state][n-1] > score:\n",
    "                last = state\n",
    "                score = viterbi[state][n-1]\n",
    "        path = [last]\n",
    "        # backtrack to recreate max likelihood hidden_path in reverse\n",
    "        i = n-1\n",
    "        while i > 0:\n",
    "            next = pointers[last][i]\n",
    "            path.append(next)\n",
    "            last = next\n",
    "            i -= 1\n",
    "        # reverse string to get hidden_path     \n",
    "        return path[::-1]\n",
    "\n",
    "    def estimate_parameters(pi, x, S, alpha):\n",
    "        \"\"\"Adjusts parameters based on hidden path pi and emit string x\"\"\"\n",
    "        T = np.zeros(shape = (S, S))\n",
    "        E = np.zeros(shape = (S, len(alpha)))\n",
    "        E[pi[0]][x[0]] +=1\n",
    "        prev = pi[0]\n",
    "        for i in range(1, len(x)):\n",
    "            E[pi[i]][x[i]] +=1\n",
    "            T[prev][pi[i]] +=1\n",
    "            prev = pi[i]\n",
    "        for s in range(S):\n",
    "            if sum(E[s]) == 0:\n",
    "                E[s]+=1\n",
    "            E[s] = E[s]/sum(E[s])\n",
    "            if sum(T[s]) == 0:\n",
    "                T[s] += 1\n",
    "            T[s] = T[s]/sum(T[s])\n",
    "        return T,E\n",
    "    \n",
    "    # Convert emissions x to integers list\n",
    "    x = [int(alpha.index(emission)) for emission in x]\n",
    "    S = len(states)\n",
    "    \n",
    "    # E-M algorithm\n",
    "    for r in range(iters):\n",
    "        # viterbi algo to find optimal hidden path | HMM, x\n",
    "        pi = viterbi_hiddenpath(x, T, E, S)\n",
    "        # estimate HMM parameters | pi, x\n",
    "        T, E = estimate_parameters(pi, x, S, alpha)\n",
    "    print(\"Final hidden path pi\", pi)\n",
    "    return (T, E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outputHMM(T,E,S,alpha):\n",
    "    lists = []\n",
    "    lists.append(['']+S)\n",
    "    for i in range(len(S)):\n",
    "        # use {0:g} format to remove trailing zeros\n",
    "        lists.append([S[i]]+['{0:g}'.format(x) for x in T[i]])\n",
    "    lists.append('--------')\n",
    "    lists.append([''] + alpha)\n",
    "    for i in range(len(S)):\n",
    "        lists.append([S[i]]+['{0:g}'.format(x) for x in E[i]])\n",
    "    return lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 zzzyyxyzzzxyxzxxzzyxxzzzzzzyzxyzxxxzxxxzyzzxzxzzzxyzyyyxxxxzxyyyyyxzzzyxyzzxxzxxzxyxyxyzxzxzxzyxyzzz ['x', 'y', 'z'] ['A', 'B']\n",
      "[[0.436 0.564]\n",
      " [0.953 0.047]]\n",
      "[[0.367 0.248 0.385]\n",
      " [0.401 0.361 0.238]]\n",
      "Final hidden path pi [1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0]\n",
      "\n",
      "\n",
      "estimated Transition matrix:\n",
      "\n",
      "[[0. 1.]\n",
      " [1. 0.]]\n",
      "\n",
      "estimated Emission matrix:\n",
      "\n",
      "[[0.36 0.14 0.5 ]\n",
      " [0.34 0.34 0.32]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with open(\"/Users/jasonmoggridge/Dropbox/Rosalind/Coursera_textbook_track/Course6/data/ba10i.extra.txt\") as f:\n",
    "    lines = [line.strip() for line in f]\n",
    "    # number of iterations 'iters'\n",
    "    iters = int(lines[0].strip())\n",
    "    # string emitted by HMM 'x'\n",
    "    x = lines[2].strip()\n",
    "    # alphabet of emissions from HMM in x; convert x to integers\n",
    "    alpha = lines[4].split()\n",
    "    # states of HMM\n",
    "    states = lines[6].split()\n",
    "    # Transition matrix\n",
    "    T = np.array([line.split()[1:] for line in lines[9:9+len(states)]], float)\n",
    "    #Emission matrix\n",
    "    E = np.array([line.split()[1:] for line in lines[9+len(states)+2:]], float)\n",
    "\n",
    "print(iters,x,alpha, states)\n",
    "print(T)\n",
    "print(E)\n",
    "\n",
    "# Learn HMM from input string and random HMM to start.\n",
    "(T, E) = viterbi_learning(x,T,E, states, alpha)\n",
    "\n",
    "# T = pd.DataFrame(np.around(T,3), index=states, columns = states)\n",
    "# E = pd.DataFrame(np.around(E,3), index=states, columns = alpha)                 \n",
    "print(\"\\n\\nestimated Transition matrix:\\n\")\n",
    "print(T)\n",
    "print(\"\\nestimated Emission matrix:\\n\")\n",
    "print(E)\n",
    "\n",
    "outdata = outputHMM(T, E, states, alpha)\n",
    "\n",
    "with open('/Users/jasonmoggridge/Dropbox/Rosalind/Coursera_textbook_track/Course6/data/10i.extra.out.txt','w') as file:\n",
    "    for line in outdata[:-1]:\n",
    "        if line[0] != '-':\n",
    "            file.write('\\t'.join(line))\n",
    "        else:\n",
    "            file.write(line)\n",
    "        file.write('\\n')\n",
    "    file.write('\\t'.join(outdata[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### my solution:\n",
    "\n",
    "    estimated Transition matrix:\n",
    "             A    B\n",
    "        A  0.0  1.0\n",
    "        B  1.0  0.0\n",
    "\n",
    "    estimated Emission matrix:\n",
    "              x     y     z\n",
    "        A  0.36  0.14  0.50\n",
    "        B  0.34  0.34  0.32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "### Stepik test dataset\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def viterbi_learning(x, T, E, states, alpha):\n",
    "    \"\"\"Learn HMM given emission string x and initial HMM; return HMM: T, E matrices\"\"\"\n",
    "\n",
    "    def viterbi_hiddenpath(x, T, E, S):\n",
    "        \"\"\"returns max likelihood hidden path for emission string, given HMM\"\"\"\n",
    "\n",
    "        n = len(x)\n",
    "        viterbi = np.ones(shape = (S, n)) * -float('inf')\n",
    "        pointers = [[False for e in range(n)] for s in range(S)] \n",
    "        # init first column of viterbi with Pr_emission & 1/States\n",
    "        for state in range(S):\n",
    "            viterbi[state][0] = np.log(1/S) + E[state][x[0]]\n",
    "            pointers[state][0] = -1\n",
    "\n",
    "        # Fill viterbi graph using dynamic programming\n",
    "\n",
    "        for i in range(1,n):\n",
    "            for state in range(S):\n",
    "                for prev in range(S):\n",
    "                    p_total = E[state][x[i]] + T[prev][state] + viterbi[prev][i-1]\n",
    "                    if p_total > viterbi[state][i]:\n",
    "                        viterbi[state][i] = p_total\n",
    "                        pointers[state][i] = prev\n",
    "        # start backtrack from greatest probability in last column of viterbi\n",
    "        score = -float('inf')\n",
    "        for state in range(S):\n",
    "            if viterbi[state][n-1] > score:\n",
    "                last = state\n",
    "                score = viterbi[state][n-1]\n",
    "        path = [last]\n",
    "        # backtrack to recreate max likelihood hidden_path in reverse\n",
    "        i = n-1\n",
    "        while i > 0:\n",
    "            next = pointers[last][i]\n",
    "            path.append(next)\n",
    "            last = next\n",
    "            i -= 1\n",
    "        # reverse string to get hidden_path     \n",
    "        return path[::-1]\n",
    "\n",
    "    def estimate_parameters(pi, x, S, alpha):\n",
    "        \"\"\"Adjusts parameters based on hidden path pi and emit string x\"\"\"\n",
    "        T = np.zeros(shape = (S, S))\n",
    "        E = np.zeros(shape = (S, len(alpha)))\n",
    "        E[pi[0]][x[0]] +=1\n",
    "        prev = pi[0]\n",
    "        for i in range(1, len(x)):\n",
    "            E[pi[i]][x[i]] +=1\n",
    "            T[prev][pi[i]] +=1\n",
    "            prev = pi[i]\n",
    "        for s in range(S):\n",
    "            if sum(E[s]) == 0:\n",
    "                E[s]+=1\n",
    "            E[s] = E[s]/sum(E[s])\n",
    "            if sum(T[s]) == 0:\n",
    "                T[s] += 1\n",
    "            T[s] = T[s]/sum(T[s])\n",
    "        return T,E\n",
    "    \n",
    "    # Convert emissions x to integers list\n",
    "    x = [int(alpha.index(emission)) for emission in x]\n",
    "    S = len(states)\n",
    "    \n",
    "    # E-M algorithm\n",
    "    for r in range(iters):\n",
    "        # viterbi algo to find optimal hidden path | HMM, x\n",
    "        pi = viterbi_hiddenpath(x, T, E, S)\n",
    "        # estimate HMM parameters | pi, x\n",
    "        T, E = estimate_parameters(pi, x, S, alpha)\n",
    "    print(\"Final hidden path pi\", pi)\n",
    "    return (T, E)\n",
    "\n",
    "\n",
    "def outputHMM(T,E,S,alpha):\n",
    "    lists = []\n",
    "    lists.append(['']+S)\n",
    "    for i in range(len(S)):\n",
    "        # use {0:g} format to remove trailing zeros\n",
    "        lists.append([S[i]]+['{0:g}'.format(x) for x in T[i]])\n",
    "    lists.append('--------')\n",
    "    lists.append([''] + alpha)\n",
    "    for i in range(len(S)):\n",
    "        lists.append([S[i]]+['{0:g}'.format(x) for x in E[i]])\n",
    "    print(lists)\n",
    "    return lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 xyxyxzyyxxxxxxyxyxxzxzxzyyxyxzyyzyyxyyxzzzxyyzyyyzxzxyzyxzzyxxxxxyxzyyxxyzzzyxzxzyxzzxxxzxyyxyyzxyyz ['x', 'y', 'z'] ['A', 'B']\n",
      "[[0.261 0.739]\n",
      " [0.18  0.82 ]]\n",
      "[[0.078 0.475 0.447]\n",
      " [0.211 0.213 0.576]]\n",
      "Final hidden path pi [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "\n",
      "\n",
      "estimated Transition matrix:\n",
      "\n",
      "[[0.5 0.5]\n",
      " [0.  1. ]]\n",
      "\n",
      "estimated Emission matrix:\n",
      "\n",
      "[[0.33333333 0.33333333 0.33333333]\n",
      " [0.39       0.35       0.26      ]]\n",
      "[['', 'A', 'B'], ['A', '0.5', '0.5'], ['B', '0', '1'], '--------', ['', 'x', 'y', 'z'], ['A', '0.333333', '0.333333', '0.333333'], ['B', '0.39', '0.35', '0.26']]\n"
     ]
    }
   ],
   "source": [
    "### MAIN:\n",
    "\n",
    "with open(\"/Users/jasonmoggridge/Dropbox/Rosalind/Coursera_textbook_track/Course6/data/dataset_26260_8.txt\") as f:\n",
    "    lines = [line.strip() for line in f]\n",
    "    # number of iterations 'iters'\n",
    "    iters = int(lines[0].strip())\n",
    "    # string emitted by HMM 'x'\n",
    "    x = lines[2].strip()\n",
    "    # alphabet of emissions from HMM in x; convert x to integers\n",
    "    alpha = lines[4].split()\n",
    "    # states of HMM\n",
    "    states = lines[6].split()\n",
    "    # Transition matrix\n",
    "    T = np.array([line.split()[1:] for line in lines[9:9+len(states)]], float)\n",
    "    #Emission matrix\n",
    "    E = np.array([line.split()[1:] for line in lines[9+len(states)+2:]], float)\n",
    "\n",
    "print(iters,x,alpha, states)\n",
    "print(T)\n",
    "print(E)\n",
    "\n",
    "# Learn HMM from input string and random HMM to start.\n",
    "(T, E) = viterbi_learning(x,T,E, states, alpha)\n",
    "\n",
    "# T = pd.DataFrame(np.around(T,3), index=states, columns = states)\n",
    "# E = pd.DataFrame(np.around(E,3), index=states, columns = alpha)                 \n",
    "print(\"\\n\\nestimated Transition matrix:\\n\")\n",
    "print(T)\n",
    "print(\"\\nestimated Emission matrix:\\n\")\n",
    "print(E)\n",
    "\n",
    "outdata = outputHMM(T, E, states, alpha)\n",
    "\n",
    "with open('/Users/jasonmoggridge/Dropbox/Rosalind/Coursera_textbook_track/Course6/data/0UT.out.txt','w') as file:\n",
    "    for line in outdata[:-1]:\n",
    "        if line[0] != '-':\n",
    "            file.write('\\t'.join(line))\n",
    "        else:\n",
    "            file.write(line)\n",
    "        file.write('\\n')\n",
    "    file.write('\\t'.join(outdata[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "### Rosalind dataset\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 yzyyzxzyyzxyzzxxyzyzyxyyzzzyzzxxyxyzyyzxxzxzzzxzxyzxxyxxyzzyyyxzzyyzxzxzyzzxzzyzzxxyxyyzyyyyzzzxyyzy ['x', 'y', 'z'] ['A', 'B']\n",
      "[[0.959 0.041]\n",
      " [0.543 0.457]]\n",
      "[[0.682 0.275 0.043]\n",
      " [0.601 0.077 0.322]]\n",
      "Final hidden path pi [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "\n",
      "estimated Transition matrix:\n",
      "\n",
      "[[1.  0. ]\n",
      " [0.5 0.5]]\n",
      "\n",
      "estimated Emission matrix:\n",
      "\n",
      "[[0.25  0.36  0.39 ]\n",
      " [0.333 0.333 0.333]]\n",
      "[['', 'A', 'B'], ['A', '1', '0'], ['B', '0.5', '0.5'], '--------', ['', 'x', 'y', 'z'], ['A', '0.25', '0.36', '0.39'], ['B', '0.333', '0.333', '0.333']]\n"
     ]
    }
   ],
   "source": [
    "### MAIN:\n",
    "\n",
    "with open(\"/Users/jasonmoggridge/Dropbox/Rosalind/Coursera_textbook_track/Course6/data/rosalind_ba10i.txt\") as f:\n",
    "    lines = [line.strip() for line in f]\n",
    "    # number of iterations 'iters'\n",
    "    iters = int(lines[0].strip())\n",
    "    # string emitted by HMM 'x'\n",
    "    x = lines[2].strip()\n",
    "    # alphabet of emissions from HMM in x; convert x to integers\n",
    "    alpha = lines[4].split()\n",
    "    # states of HMM\n",
    "    states = lines[6].split()\n",
    "    # Transition matrix\n",
    "    T = np.array([line.split()[1:] for line in lines[9: 9+len(states)]], float)\n",
    "    #Emission matrix\n",
    "    E = np.array([line.split()[1:] for line in lines[9+len(states)+2:]], float)\n",
    "\n",
    "print(iters, x, alpha, states)\n",
    "print(T)\n",
    "print(E)\n",
    "\n",
    "# Learn HMM from input string and random HMM to start.\n",
    "(T, E) = viterbi_learning(x, T, E, states, alpha)\n",
    "\n",
    "T = np.around(T, 3)\n",
    "E = np.around(E, 3)\n",
    "print(\"\\n\\nestimated Transition matrix:\\n\")\n",
    "print(T)\n",
    "print(\"\\nestimated Emission matrix:\\n\")\n",
    "print(E)\n",
    "\n",
    "outdata = outputHMM(T, E, states, alpha)\n",
    "\n",
    "with open('/Users/jasonmoggridge/Dropbox/Rosalind/Coursera_textbook_track/Course6/data/0UT.ba10i.txt','w') as file:\n",
    "    for line in outdata[:-1]:\n",
    "        if line[0] != '-':\n",
    "            file.write('\\t'.join(line))\n",
    "        else:\n",
    "            file.write(line)\n",
    "        file.write('\\n')\n",
    "    file.write('\\t'.join(outdata[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solved, had a little bug in output formatting with rounding (needs to be 3, no trailing zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
