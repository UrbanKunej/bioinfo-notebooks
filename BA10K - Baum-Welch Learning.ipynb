{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baum-Welch Learning algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "\n",
    "**Exercise Break**: Consider the following questions.\n",
    "\n",
    "For the crooked dealer HMM, compute Pr(πi = k|x) for x = “THTHHHTHTTH” and each value of i.  \n",
    "How does your answer change if x = “HHHHHHHHHHH”?  \n",
    "\n",
    "<br>\n",
    "\n",
    "<img src = http://bioinformaticsalgorithms.com/images/HMM/HMM_diagram_complete.png width = 400px>\n",
    "\n",
    "<br>\n",
    "\n",
    "##### Apply your solution for the Soft Decoding Problem to find CG-islands in the first million nucleotides from the human X chromosome. How does your answer differ from the solution given by the Viterbi algorithm?\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(X, T, E, S): # forward outcome likelihood\n",
    "    F = np.zeros(shape = (S, len(X))) \n",
    "    for state in range(S):\n",
    "        F[state][0] = E[state][X[0]] / S\n",
    "    for i in range(1,len(X)):\n",
    "        for state in range(S):\n",
    "            F[state][i] = sum(T[k][state]*F[k][i-1] for k in range(S))\n",
    "            F[state][i] *= E[state][X[i]]\n",
    "    return F\n",
    "def backward(X, T, E, S): # slightly different recurrence\n",
    "    B = np.ones(shape = (S, len(X))) # last column nodes = 1\n",
    "    for i in range(len(X)-2, -1, -1): \n",
    "        for state in range(S):\n",
    "            B[state][i] = sum(T[state][k] * B[k][i+1] * E[k][X[i+1]] for k in range(S))\n",
    "    return B\n",
    "def forward_backward(X,T,E,S):\n",
    "    \"\"\"returns responsibility matrix for states\"\"\"    \n",
    "    F = forward(X, T, E, S)\n",
    "    B = backward(X, T, E, S)\n",
    "    F_sink = sum(F[state][len(X)-1] for state in range(S))\n",
    "    return np.multiply(F, B)/F_sink\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# when string is 1 0 1 0 0 0 1 0 1 1 0\n",
      "       0      1    2      3      4      5      6      7      8      9     10\n",
      "F  0.636  0.593  0.6  0.533  0.515  0.544  0.627  0.633  0.692  0.686  0.609\n",
      "B  0.364  0.407  0.4  0.467  0.485  0.456  0.373  0.367  0.308  0.314  0.391\n",
      "\n",
      "# when string is all heads\n",
      "       0      1      2      3      4      5      6      7      8      9     10\n",
      "F  0.175  0.134  0.109  0.095  0.087  0.085  0.087  0.095  0.109  0.134  0.175\n",
      "B  0.825  0.866  0.891  0.905  0.913  0.915  0.913  0.905  0.891  0.866  0.825\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# crooked casino hmm\n",
    "T = [[0.9, 0.1], [0.1,0.9]]\n",
    "E = [[0.5, 0.5], [0.75,0.25]]\n",
    "S = 2\n",
    "\n",
    "# given string with varied sequence\n",
    "X = [int(i) for i in \"1 0 1 0 0 0 1 0 1 1 0\".split(' ')]\n",
    "Pi_star = forward_backward(X,T,E,S)\n",
    "Pi_star = pd.DataFrame(np.around(Pi_star,3), index = (\"F\", \"B\"))\n",
    "print(\"\\n# when string is 1 0 1 0 0 0 1 0 1 1 0\")\n",
    "print(Pi_star)\n",
    "\n",
    "# when string is all heads\n",
    "X =[0 for _ in range(len(X))]\n",
    "Pi_star = forward_backward(X,T,E,S)\n",
    "Pi_star = pd.DataFrame(np.around(Pi_star,3), index = (\"F\", \"B\"))\n",
    "print(\"\\n# when string is all heads\")\n",
    "print(Pi_star)\n",
    "\n",
    "X = [int(i) for i in \"1 0 1 0 0 0 1 0 1 1 0\".split(' ')]\n",
    "Pi_star = forward_backward(X,T,E,S)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<br>\n",
    "\n",
    "We have just seen how to compute the **conditional probability $Pr(π_i = k|x)$ that the HMM passes through node (k, i)** in the Viterbi graph given that the HMM emits x.  \n",
    "\n",
    "But what about **the conditional probability $Pr(π_i = l, π_{i+1} = k|x)$ that the HMM passes through the edge** connecting (l, i) to (k, i + 1) given that the HMM emits x?  \n",
    "\n",
    "As with the forward-backward algorithm, we can divide every path through the edge in question into a blue path from $source$ to this edge and a red path from this edge to $sink$ (see figure below).\n",
    "\n",
    "<img src =http://bioinformaticsalgorithms.com/images/HMM/forward_edge.png width = 500px>\n",
    "\n",
    "**Exercise Break:**\n",
    "Prove that $Pr(π_i = l, π_{i+1} = k|x)$ is equal to $forward(l, i) \\cdot Weighti(l, k) \\cdot backward(k,i+1) / forward(sink)$.\n",
    "\n",
    "\n",
    "\n",
    "**Figure**: Each path from source to sink in the Viterbi graph passing through the (black) edge (l, i) → (k, i + 1) in the Viterbi graph can be partitioned into two subpaths, one from source to (l, i) (shown in blue) and another from (k, i + 1) to sink (shown in red).\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "The probabilities $Pr(π_i = k|x)$ can be put into a $|States| × n$ **responsibility matrix Π∗**, where $Π∗(k, i)$ corresponds to a node in the Viterbi graph and is equal to $Pr(π_i = k|x)$. The figure below (top) shows the “responsibility” matrix Π∗ for the crooked casino.\n",
    "\n",
    "The probabilities $Pr(π_i = l, π_{i+1} = k|x)$ can be put into another $|States| × |States| × (n − 1)$ **responsibility matrix Π∗∗**, where $Π∗∗(l, k, i)$ corresponds to an edge in the Viterbi graph and is equal to $Pr(π_i = l, π_{i+1} = k|x)$ (figure below (bottom)). For brevity, we use **Π to collectively refer to the matrices Π∗ and Π∗∗.**\n",
    "\n",
    "**Exercise Break**: What is the complexity of an algorithm computing the matrices Π∗ and Π∗∗?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0), (0, 1), (1, 0), (1, 1)]\n",
      "\n",
      "\n",
      "PiStar:\n",
      "        0      1    2      3      4      5      6      7      8      9     10\n",
      "F  0.636  0.593  0.6  0.533  0.515  0.544  0.627  0.633  0.692  0.686  0.609\n",
      "B  0.364  0.407  0.4  0.467  0.485  0.456  0.373  0.367  0.308  0.314  0.391 \n",
      "\n",
      "Pi_2Star:\n",
      "             0      1      2      3      4      5      6      7      8      9\n",
      "(0, 0)  0.562  0.548  0.507  0.473  0.478  0.523  0.582  0.608  0.643  0.588\n",
      "(0, 1)  0.074  0.045  0.093  0.059  0.037  0.022  0.045  0.025  0.049  0.098\n",
      "(1, 0)  0.031  0.053  0.025  0.042  0.066  0.104  0.051  0.084  0.043  0.022\n",
      "(1, 1)  0.333  0.354  0.374  0.426  0.418  0.351  0.322  0.282  0.265  0.293\n"
     ]
    }
   ],
   "source": [
    "# crooked casino hmm\n",
    "T = [[0.9, 0.1], [0.1,0.9]]\n",
    "E = [[0.5, 0.5], [0.75,0.25]]\n",
    "S = 2\n",
    "\n",
    "# emitted string\n",
    "X = [int(i) for i in \"1 0 1 0 0 0 1 0 1 1 0\".split(' ')]\n",
    "\n",
    "# calculate responsibility matrices Pi_star and Pi_2star\n",
    "F = forward(X, T, E, S)\n",
    "B = backward(X, T, E, S)\n",
    "F_sink = sum(F[state][len(X)-1] for state in range(S))\n",
    "Pi_star = forward_backward(X,T,E,S)\n",
    "\n",
    "\n",
    "transitions = list((l,k) for l in range(S) for k in range(S))\n",
    "print(transitions)\n",
    "\n",
    "Pi_2star = np.zeros(shape = (len(transitions), len(X)-1))\n",
    "for i in range(len(X)-1):\n",
    "    for t in range(len(T)**2):\n",
    "        (l,k) = transitions[t]\n",
    "        weight_edge = E[k][X[i+1]] * T[l][k]\n",
    "        Pi_2star[t][i] = F[l][i] * weight_edge * B[k][i+1] / F_sink\n",
    "\n",
    "\n",
    "Pi_star = pd.DataFrame(np.around(Pi_star,3), index = (\"F\",\"B\"))\n",
    "Pi_2star = pd.DataFrame(np.around(Pi_2star,3), index = transitions)\n",
    "print(\"\\n\\nPiStar:\\n\", Pi_star,\"\\n\\nPi_2Star:\\n\",Pi_2star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new forward-backward algorithm that returns π = {π*, π**}\n",
    "\n",
    "def forward_backward(X,T,E,S):\n",
    "    \"\"\"returns responsibility matrix for states\"\"\"    \n",
    "    \n",
    "    def forward(X, T, E, S): # forward outcome likelihood\n",
    "        F = np.zeros(shape = (S, len(X))) \n",
    "        for state in range(S):\n",
    "            F[state][0] = E[state][X[0]] / S\n",
    "        for i in range(1,len(X)):\n",
    "            for state in range(S):\n",
    "                F[state][i] = sum(T[k][state]*F[k][i-1] for k in range(S))\n",
    "                F[state][i] *= E[state][X[i]]\n",
    "        return F\n",
    "      \n",
    "    def backward(X, T, E, S): # slightly different recurrence\n",
    "        B = np.ones(shape = (S, len(X))) # last column nodes = 1\n",
    "        for i in range(len(X)-2, -1, -1): \n",
    "            for state in range(S):\n",
    "                B[state][i] = sum(T[state][k] * B[k][i+1] * E[k][X[i+1]] for k in range(S))\n",
    "        return B\n",
    "    \n",
    "    transitions = list((l,k) for l in range(S) for k in range(S))    \n",
    "    F = forward(X, T, E, S)\n",
    "    B = backward(X, T, E, S)\n",
    "    F_sink = sum(F[state][len(X)-1] for state in range(S))\n",
    "    \n",
    "    pi_star = np.multiply(F, B)/F_sink\n",
    "    pi_2star = np.zeros(shape = (len(T)**2, len(X)-1))\n",
    "    for i in range(len(X)-1):\n",
    "        for t in range(len(T)**2):\n",
    "            (l,k) = transitions[t]\n",
    "            weight_edge = E[k][X[i+1]] * T[l][k]\n",
    "            pi_2star[t][i] = F[l][i] * weight_edge * B[k][i+1]\n",
    "    pi_2star = pi_2star/ F_sink\n",
    "    return pi_star, pi_2star\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0] \n",
      "\n",
      "PiStar:\n",
      "        0      1    2      3      4      5      6      7      8      9     10\n",
      "F  0.636  0.593  0.6  0.533  0.515  0.544  0.627  0.633  0.692  0.686  0.609\n",
      "B  0.364  0.407  0.4  0.467  0.485  0.456  0.373  0.367  0.308  0.314  0.391 \n",
      "\n",
      "Pi_2Star:\n",
      "             0      1      2      3      4      5      6      7      8      9\n",
      "(0, 0)  0.562  0.548  0.507  0.473  0.478  0.523  0.582  0.608  0.643  0.588\n",
      "(0, 1)  0.074  0.045  0.093  0.059  0.037  0.022  0.045  0.025  0.049  0.098\n",
      "(1, 0)  0.031  0.053  0.025  0.042  0.066  0.104  0.051  0.084  0.043  0.022\n",
      "(1, 1)  0.333  0.354  0.374  0.426  0.418  0.351  0.322  0.282  0.265  0.293\n"
     ]
    }
   ],
   "source": [
    "X = [int(i) for i in \"1 0 1 0 0 0 1 0 1 1 0\".split(' ')]\n",
    "Pi_s, Pi_ss = forward_backward(X,T,E,S)\n",
    "\n",
    "Pi_star = pd.DataFrame(np.around(Pi_s,3), index = (\"F\",\"B\"))\n",
    "Pi_2star = pd.DataFrame(np.around(Pi_ss,3), index = transitions)\n",
    "print(X,\"\\n\\nPiStar:\\n\", Pi_star,\"\\n\\nPi_2Star:\\n\",Pi_2star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = http://bioinformaticsalgorithms.com/images/HMM/responsibility_matrices.png width = 500px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def estimate_parameters(X, Pi_s, Pi_ss, alpha):\n",
    "    \"\"\"from π*, derive E, T parameters froms sums in responsibility matrices\"\"\"\n",
    "    transitions = list((l,k) for l in range(S) for k in range(S))    \n",
    "    E = np.zeros(shape=(S,len(alpha)))\n",
    "    T = np.zeros(shape=(S,S))\n",
    "    for i in range(len(X)):\n",
    "        for k in range(S):\n",
    "            E[k][X[i]] += Pi_s[k][i]\n",
    "    for i in range(len(X)-1):\n",
    "        for t in range(len(transitions)):\n",
    "            (l,k) = transitions[t]\n",
    "            T[l][k] += Pi_ss[t][i]\n",
    "    T_sums = T.sum(axis=1)\n",
    "    T =  T/ T_sums[:, np.newaxis]\n",
    "    E_sums = E.sum(axis=1)\n",
    "    E =  E/ E_sums[:, np.newaxis]        \n",
    "    return T,E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "E:\n",
      "       0      1\n",
      "0  0.514  0.486\n",
      "1  0.594  0.406\n",
      "\n",
      "T:\n",
      "       0      1\n",
      "0  0.910  0.090\n",
      "1  0.132  0.868\n"
     ]
    }
   ],
   "source": [
    "# crooked casino hmm\n",
    "T = [[0.9, 0.1], [0.1,0.9]]\n",
    "E = [[0.5, 0.5], [0.75,0.25]]\n",
    "S = 2\n",
    "#string\n",
    "X = [int(i) for i in \"1 0 1 0 0 0 1 0 1 1 0\".split(' ')]\n",
    "alpha = [0,1]\n",
    "\n",
    "Pi_s, Pi_ss = forward_backward(X,T,E,S)\n",
    "T, E = estimate_parameters(X, Pi_s, Pi_ss, alpha)\n",
    "\n",
    "# T_sums = T.sum(axis=1)\n",
    "# T =  T/ T_sums[:, np.newaxis]\n",
    "# E_sums = E.sum(axis=1)\n",
    "# E =  E/ E_sums[:, np.newaxis]\n",
    "\n",
    "print(\"\\nE:\")\n",
    "print(pd.DataFrame(np.around(E,3)))\n",
    "print(\"\\nT:\")\n",
    "print(pd.DataFrame(np.around(T,3)))\n",
    "\n",
    "\n",
    "# print(\"\\nE:\")\n",
    "# print(pd.DataFrame(np.around(EE,3)))\n",
    "# print(\"\\nT:\")\n",
    "# print(pd.DataFrame(np.around(TT,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### Baum-Welch Learning\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def parse_BaumWelch_file(filepath):\n",
    "    with open(filepath,'r') as file:\n",
    "        inputs = file.readlines()\n",
    "    iters = int(inputs[0].strip())\n",
    "    alpha = inputs[4].strip().split()\n",
    "    X = list(alpha.index(x) for x in inputs[2].strip())\n",
    "    states = inputs[6].strip().split()\n",
    "    S = len(states)\n",
    "    # HMM Transition, emission matrices,\n",
    "    T = np.array([line.split()[1:] for line in inputs[9: 9+S]], float)\n",
    "    E = np.array([line.split()[1:] for line in inputs[9+S+2:]], float)\n",
    "    return iters, X, alpha, T, E, S, states\n",
    "\n",
    "\n",
    "# new forward-backward algorithm that returns π =\n",
    "def forward_backward(X,T,E,S):\n",
    "    \"\"\"E-step (X, θ) -> π (π*, π**)\"\"\"    \n",
    "    def forward(X, T, E, S): # forward outcome likelihood\n",
    "        F = np.zeros(shape = (S, len(X))) \n",
    "        for state in range(S):\n",
    "            F[state][0] = E[state][X[0]] / S\n",
    "        for i in range(1,len(X)):\n",
    "            for state in range(S):\n",
    "                F[state][i] = sum(T[k][state]*F[k][i-1] for k in range(S))\n",
    "                F[state][i] *= E[state][X[i]]\n",
    "        return F\n",
    "    def backward(X, T, E, S): # slightly different recurrence\n",
    "        B = np.ones(shape = (S, len(X))) # last column nodes = 1\n",
    "        for i in range(len(X)-2, -1, -1): \n",
    "            for state in range(S):\n",
    "                B[state][i] = sum(T[state][k] * B[k][i+1] * E[k][X[i+1]] for k in range(S))\n",
    "        return B\n",
    "    F = forward(X, T, E, S)\n",
    "    B = backward(X, T, E, S)\n",
    "    F_sink = sum(F[state][len(X)-1] for state in range(S))\n",
    "    pi_star = np.multiply(F, B)/F_sink\n",
    "    pi_2star = np.zeros(shape = (len(T)**2, len(X)-1))\n",
    "    transitions = list((l,k) for l in range(S) for k in range(S))    \n",
    "    for i in range(len(X)-1):\n",
    "        for t in range(len(T)**2):\n",
    "            (l,k) = transitions[t]\n",
    "            weight_edge = E[k][X[i+1]] * T[l][k]\n",
    "            pi_2star[t][i] = F[l][i] * weight_edge * B[k][i+1]\n",
    "    pi_2star = pi_2star/ F_sink\n",
    "    return pi_star, pi_2star\n",
    "\n",
    "def estimate_parameters(X, Pi_s, Pi_ss, alpha, S):\n",
    "    \"\"\"M-step: (X, π) -> θ (T,E)\"\"\"\n",
    "    transitions = list((l,k) for l in range(S) for k in range(S))    \n",
    "    E = np.zeros(shape=(S,len(alpha)))\n",
    "    T = np.zeros(shape=(S,S))\n",
    "    for i in range(len(X)):\n",
    "        for k in range(S):\n",
    "            E[k][X[i]] += Pi_s[k][i]\n",
    "    for i in range(len(X)-1):\n",
    "        for t in range(len(transitions)):\n",
    "            (l,k) = transitions[t]\n",
    "            T[l][k] += Pi_ss[t][i]\n",
    "    T_sums = T.sum(axis=1)\n",
    "    T =  T/ T_sums[:, np.newaxis]\n",
    "    E_sums = E.sum(axis=1)\n",
    "    E =  E/ E_sums[:, np.newaxis]        \n",
    "    return T,E\n",
    "\n",
    "def baum_welch_learning(X,T,E,S, alpha, iters):\n",
    "    \"\"\"returns HMM paramters learned from emitted string X\"\"\"\n",
    "    for _ in range(iters):\n",
    "        # E-step\n",
    "        Pi_s, Pi_ss = forward_backward(X,T,E,S)\n",
    "        # M- step\n",
    "        T, E = estimate_parameters(X, Pi_s, Pi_ss, alpha, S)\n",
    "    return T, E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jasonmoggridge/Dropbox/Rosalind/Coursera_textbook_track/Course6/data\n",
      "10 [0, 2, 1, 1, 2, 1, 2, 1, 0, 1] ['x', 'y', 'z'] [[0.019 0.981]\n",
      " [0.668 0.332]] [[0.175 0.003 0.821]\n",
      " [0.196 0.512 0.293]] 2 ['A', 'B']\n",
      "       x      y      z\n",
      "A  0.242  0.000  0.758\n",
      "B  0.172  0.828  0.000\n",
      "       A      B\n",
      "A  0.000  1.000\n",
      "B  0.786  0.214\n",
      "/Users/jasonmoggridge/Dropbox/Rosalind/Coursera_textbook_track/Course6/results\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%cd /Users/jasonmoggridge/Dropbox/Rosalind/Coursera_textbook_track/Course6/data\n",
    "iters, X, alpha, T, E, S, states = parse_BaumWelch_file(\"BA10K.sample.txt\")\n",
    "print(iters, X, alpha, T, E, S, states)\n",
    "T,E = baum_welch_learning(X,T,E,S, alpha, iters)\n",
    "E = pd.DataFrame(np.around(E,3), index= states, columns = alpha)\n",
    "T = pd.DataFrame(np.around(T,3), index= states, columns = states)\n",
    "print(E)\n",
    "print(T)\n",
    "%cd /Users/jasonmoggridge/Dropbox/Rosalind/Coursera_textbook_track/Course6/results/\n",
    "T.to_csv(\"BA10k.sample.out.txt\", sep ='\\t')\n",
    "with open(\"BA10k.sample.out.txt\",'a') as f:\n",
    "    f.write('--------\\n')\n",
    "E.to_csv(\"BA10k.sample.out.txt\", mode = 'a', sep='\\t')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jasonmoggridge/Dropbox/Rosalind/Coursera_textbook_track/Course6/data\n",
      "100 [1, 2, 0, 0, 2, 0, 2, 0, 0, 1, 2, 1, 0, 2, 2, 2, 0, 1, 1, 2, 0, 2, 1, 1, 2, 0, 1, 2, 2, 1, 0, 0, 2, 2, 2, 0, 2, 1, 1, 2, 1, 1, 1, 0, 2, 0, 1, 0, 2, 0, 0, 1, 2, 1, 0, 0, 0, 0, 2, 0, 0, 1, 1, 0, 1, 2, 1, 2, 2, 2, 0, 1, 2, 1, 2, 1, 2, 0, 1, 1, 1, 0, 1, 2, 2, 2, 0, 0, 1, 1, 2, 0, 2, 2, 1, 1, 1, 2, 1, 0] ['x', 'y', 'z'] [[0.296 0.353 0.351]\n",
      " [0.569 0.303 0.128]\n",
      " [0.225 0.206 0.568]] [[0.357 0.31  0.333]\n",
      " [0.388 0.231 0.381]\n",
      " [0.316 0.279 0.404]] 3 ['A', 'B', 'C']\n",
      "       x      y      z\n",
      "A  0.642  0.351  0.007\n",
      "B  0.023  0.140  0.838\n",
      "C  0.192  0.694  0.114\n",
      "       A      B      C\n",
      "A  0.361  0.258  0.381\n",
      "B  0.675  0.309  0.015\n",
      "C  0.005  0.800  0.195\n",
      "/Users/jasonmoggridge/Dropbox/Rosalind/Coursera_textbook_track/Course6/results\n"
     ]
    }
   ],
   "source": [
    "# stepik test\n",
    "%cd /Users/jasonmoggridge/Dropbox/Rosalind/Coursera_textbook_track/Course6/data\n",
    "iters, X, alpha, T, E, S, states = parse_BaumWelch_file(\"dataset_26262_5.txt\")\n",
    "print(iters, X, alpha, T, E, S, states)\n",
    "T,E = baum_welch_learning(X,T,E,S, alpha, iters)\n",
    "E = pd.DataFrame(np.around(E,3), index= states, columns = alpha)\n",
    "T = pd.DataFrame(np.around(T,3), index= states, columns = states)\n",
    "print(E)\n",
    "print(T)\n",
    "# %cd /Users/jasonmoggridge/Dropbox/Rosalind/Coursera_textbook_track/Course6/results/\n",
    "# file = \"ba10k_stepik.txt\"\n",
    "# T.to_csv(file, sep ='\\t')\n",
    "# with open(file,'a') as f:\n",
    "#     f.write('--------\\n')\n",
    "# E.to_csv(file, mode = 'a', sep='\\t')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nailed it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jasonmoggridge/Dropbox/Rosalind/Coursera_textbook_track/Course6/data\n",
      "100 [2, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 2, 2, 2, 2, 0, 0, 1, 1, 2, 1, 2, 1, 0, 2, 2, 1, 0, 1, 1, 2, 0, 2, 0, 1, 2, 2, 0, 2, 2, 2, 1, 0, 2, 2, 0, 0, 1, 2, 1, 0, 2, 0, 0, 2, 0, 2, 1, 1, 0, 2, 0, 1, 1, 0, 2, 0, 2, 2, 0, 0, 0, 1, 2, 1, 2, 1, 2, 1, 1, 0, 0, 0, 1, 2, 2, 1, 0, 0, 0, 0, 2, 1, 1, 1, 2, 0, 2] ['x', 'y', 'z'] [[0.313 0.639 0.048]\n",
      " [0.357 0.441 0.203]\n",
      " [0.347 0.358 0.296]] [[0.225 0.309 0.466]\n",
      " [0.387 0.137 0.476]\n",
      " [0.491 0.158 0.35 ]] 3 ['A', 'B', 'C']\n",
      "       x      y      z\n",
      "A  0.146  0.555  0.299\n",
      "B  0.580  0.190  0.230\n",
      "C  0.006  0.007  0.987\n",
      "       A      B      C\n",
      "A  0.151  0.671  0.178\n",
      "B  0.445  0.486  0.069\n",
      "C  0.957  0.042  0.001\n",
      "/Users/jasonmoggridge/Dropbox/Rosalind/Coursera_textbook_track/Course6/results\n"
     ]
    }
   ],
   "source": [
    "# rosalind test\n",
    "%cd /Users/jasonmoggridge/Dropbox/Rosalind/Coursera_textbook_track/Course6/data\n",
    "iters, X, alpha, T, E, S, states = parse_BaumWelch_file(\"rosalind_ba10k.txt\")\n",
    "print(iters, X, alpha, T, E, S, states)\n",
    "T,E = baum_welch_learning(X,T,E,S, alpha, iters)\n",
    "E = pd.DataFrame(np.around(E,3), index= states, columns = alpha)\n",
    "T = pd.DataFrame(np.around(T,3), index= states, columns = states)\n",
    "print(E)\n",
    "print(T)\n",
    "%cd /Users/jasonmoggridge/Dropbox/Rosalind/Coursera_textbook_track/Course6/results/\n",
    "file = \"ba10k_rosalind.txt\"\n",
    "T.to_csv(file, sep ='\\t')\n",
    "with open(file,'a') as f:\n",
    "    f.write('--------\\n')\n",
    "E.to_csv(file, mode = 'a', sep='\\t')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "**Exercise Break**: Use Baum-Welch learning to learn parameters for the HMM modeling CG-islands and for the HIV profile HMM. Compare these parameters with parameters derived by applying Viterbi learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reached the end of the program.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
